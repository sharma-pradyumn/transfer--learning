{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_row=200\n",
    "img_col=200\n",
    "#reducing img size to 100x100 to reduce time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading model without top or Fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGG16(weights='imagenet',include_top=False,input_shape=(img_row,img_col,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D True\n",
      "2 Conv2D True\n",
      "3 MaxPooling2D True\n",
      "4 Conv2D True\n",
      "5 Conv2D True\n",
      "6 MaxPooling2D True\n",
      "7 Conv2D True\n",
      "8 Conv2D True\n",
      "9 Conv2D True\n",
      "10 MaxPooling2D True\n",
      "11 Conv2D True\n",
      "12 Conv2D True\n",
      "13 Conv2D True\n",
      "14 MaxPooling2D True\n",
      "15 Conv2D True\n",
      "16 Conv2D True\n",
      "17 Conv2D True\n",
      "18 MaxPooling2D True\n"
     ]
    }
   ],
   "source": [
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__,layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in model.layers:\n",
    "    layers.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'block5_pool/MaxPool:0' shape=(None, 6, 6, 512) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct fully connected top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_top_model(bottom_model,num_classes,D=256):\n",
    "    top_model=bottom_model.output\n",
    "    top_model=Flatten(name='flatten')(top_model)\n",
    "    top_model=Dense(512)(top_model)\n",
    "    top_model=LeakyReLU(alpha=0.1)(top_model) #adding leakyrelu instead of using relu activation in Dense\n",
    "    top_model=Dense(256)(top_model)\n",
    "    top_model=LeakyReLU(alpha=0.1)(top_model)\n",
    "    top_model=Dense(256)(top_model)\n",
    "    top_model=LeakyReLU(alpha=0.1)(top_model)\n",
    "    top_model=Dense(128)(top_model)\n",
    "    top_model=LeakyReLU(alpha=0.1)(top_model)\n",
    "    top_model=Dropout(0.3)(top_model)\n",
    "    top_model=Dense(num_classes,activation='softmax')(top_model)\n",
    "    \n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input layer specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 200, 200, 3) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All layers specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x630f2e940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630f2ee10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630f2efd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x630f5d6a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630f5d240>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630f85358>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x630f85ef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630f85d30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630f8df98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630f935f8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x630f93e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630f93f98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630f9bba8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630fa1748>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x630fa1f60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630fa8278>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630fa8cf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x630fb0898>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x630fb9320>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,LeakyReLU\n",
    "from keras.layers import MaxPooling2D,Conv2D,ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venv-3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "FC_head=add_top_model(model,num_classes)\n",
    "\n",
    "model_new=Model(inputs=model.input,output=FC_head) #Appending model and FC_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 200, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 24,383,690\n",
      "Trainable params: 9,669,002\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir='Bollywood_Dataset/Bollywood_Dataset/train'\n",
    "validation_dir='Bollywood_Dataset/Bollywood_Dataset/validation'\n",
    "train_data_gen=ImageDataGenerator(rescale=1./255,rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=False\n",
    "                                 )\n",
    "validation_data_gen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_batchsize=10\n",
    "val_batchsize=15\n",
    "\n",
    "train_generator=train_data_gen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(img_row,img_col),\n",
    "                                                   batch_size=train_batchsize,\n",
    "                                                   class_mode='categorical')\n",
    "valid_generator=validation_data_gen.flow_from_directory(validation_dir,\n",
    "                                                   target_size=(img_row,img_col),\n",
    "                                                   batch_size=val_batchsize,\n",
    "                                                   class_mode='categorical',\n",
    "                                                  shuffle=False\n",
    "                                                  )\n",
    "\n",
    "\n",
    "                            \n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training top layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "checkpoint=ModelCheckpoint('200_model.h5',\n",
    "                            monitor='val_loss',\n",
    "                            mode='min',\n",
    "                            save_best_only=True,\n",
    "                            verbose=1\n",
    "                          )\n",
    "                           \n",
    "early_stopping=EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=3,verbose=1,restore_best_weights=True)\n",
    "\n",
    "callbacks=[early_stopping,checkpoint]\n",
    "\n",
    "model_new.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=RMSprop(0.1),\n",
    "                 metrics=['accuracy'] \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 78s 4s/step - loss: 4.2236 - accuracy: 0.1200 - val_loss: 2.2521 - val_accuracy: 0.1778\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.25210, saving model to 200_model.h5\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 83s 4s/step - loss: 2.5363 - accuracy: 0.1550 - val_loss: 2.1836 - val_accuracy: 0.1529\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.25210 to 2.18359, saving model to 200_model.h5\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 75s 4s/step - loss: 2.4144 - accuracy: 0.1550 - val_loss: 2.6341 - val_accuracy: 0.2588\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.18359\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 76s 4s/step - loss: 2.3905 - accuracy: 0.1950 - val_loss: 4.1072 - val_accuracy: 0.1176\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.18359\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 70s 4s/step - loss: 2.4502 - accuracy: 0.2050 - val_loss: 1.8866 - val_accuracy: 0.0941\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.18359 to 1.88664, saving model to 200_model.h5\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 77s 4s/step - loss: 2.1926 - accuracy: 0.2150 - val_loss: 2.4472 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.88664\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 88s 4s/step - loss: 2.2077 - accuracy: 0.2650 - val_loss: 0.1131 - val_accuracy: 0.1412\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.88664 to 0.11310, saving model to 200_model.h5\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 71s 4s/step - loss: 2.2675 - accuracy: 0.2250 - val_loss: 3.3729 - val_accuracy: 0.1444\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.11310\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 67s 3s/step - loss: 2.2245 - accuracy: 0.3350 - val_loss: 2.3781 - val_accuracy: 0.3647\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.11310\n",
      "Epoch 10/10\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9615 - accuracy: 0.3263"
     ]
    }
   ],
   "source": [
    "train_samples=300\n",
    "validation_samples=100\n",
    "epochs=10\n",
    "batch_size=15\n",
    "\n",
    "classifier=model_new.fit_generator(train_generator,\n",
    "                                   steps_per_epoch=train_samples//batch_size,\n",
    "                                  epochs=epochs,\n",
    "                                  callbacks=callbacks,\n",
    "                                   validation_data=valid_generator,\n",
    "                                   validation_steps=validation_samples//batch_size\n",
    "                                  )\n",
    "                                   \n",
    "                            \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.save(\"200_model.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
